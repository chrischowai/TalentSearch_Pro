# CLAUDE.md - Essential Guidelines

## ğŸ§  CORE PRINCIPLE: Store Everything Important
**Before ANY decision/finding/error:**
```
store_daddy: Store what you learned/decided/failed (max 500 chars)
```
This prevents repeating mistakes and forgetting context.

## ğŸ“¦ PACKAGE-FIRST PHILOSOPHY

**BEFORE writing custom code, research existing packages:**

### Core Rule
- **Research first**: Use **sherlock** agent to find ecosystem packages
- **Never assume**: Always check what already exists before building custom
- **Quality over custom**: Maintained, lightweight, documented packages preferred

### Explicit Requirements
- **Icons**: Use icon packages/libraries - NEVER emojis in code
- **Common utilities**: Research standard ecosystem solutions first
- **When unsure**: Spawn sherlock to research, don't guess

### Decision Flow
```
Need functionality â†’ sherlock research â†’ Good package exists? â†’ Use it
                                     â†“
                              No good package â†’ Custom implementation
```

**Enforcement**: If you're about to implement common functionality, STOP and research first.

## ğŸ“Š VISUAL-FIRST RESPONSES

**When responding to the user:**

**Show, don't just tell:**
- Complex processes â†’ ASCII diagrams
- Multiple options â†’ Visual trees
- Status/progress â†’ Progress indicators
- Comparisons â†’ Before/after layouts

**Keep text concise and accessible for non-coders.**

## ğŸ”„ AGENT-FIRST WORKFLOW

### ğŸ¤– SPECIALIZED AGENTS (USE THESE!)

**ALWAYS use the right agent for the task:**

| Agent | When to Use |
|-------|-------------|
| **bugsy** | Errors, crashes, test failures |
| **fronty** | React/Next.js frontend work |
| **gitty** | Git operations, commits |
| **murphy** | Config validation, dependencies |
| **opinion** | Feedback, assessments |
| **scribe** | Documentation, guides |
| **sherlock** | Research, find docs/APIs |
| **validation** | Check against requirements |
| **gopher** | Go development, new Go features |
| **jsmaster** | JS/Node.js development, new JS features |
| **nextking** | Next.js apps, new Next.js features |
| **thesnake** | Python development, new Python features |
| **reactlord** | React components, new React features |
| **typegod** | TypeScript development, new TS features |
| **vuelord** | Vue.js development, new Vue features |

### ğŸš€ SINGLE vs PARALLEL AGENT STRATEGY

**Use ONE agent when:**
- Task fits clearly into one specialist's domain
- Simple, straightforward problem
- Need focused expertise

**Spawn MULTIPLE agents in parallel when:**
- Multiple file types need changes (code + config + docs)
- Errors span different domains (frontend + backend + database)  
- Research + implementation needed simultaneously
- Commands like `/check`, `/api`, `/migrate` require it

**Example parallel spawning:**
```
"I'll spawn multiple agents to handle this complex task:
- jsmaster: Write the API endpoints in files A, B, C
- murphy: Validate the database config
- sherlock: Research the latest framework patterns
Let me tackle all of these in parallel..."
```

### 1. Basic Workflow
```
1. recall_daddy: Check what we already know
2. Simple tasks: Direct implementation with appropriate agent
3. store_daddy: Store decisions and solutions
```

### 2. For Complex Tasks
```
1. recall_daddy: Check what we already know
2. add_task: Store requirements and expected results
3. Research: Read actual files (never assume)  
4. Plan: TodoWrite the steps
5. Implement: Edit/Write with verification
6. Test: Actually run the code
7. validation agent: Check against task requirements
8. store_daddy: Store what worked/failed
```

### 3. Agent Coordination
**When agent fails or gives partial results:**
- Store findings with store_daddy
- Report failure to user with specific error
- Ask user for direction (different agent, escalate, or debug)
- Share context through daddy memory system (max 5 memories)

### 4. 5-Status Task Workflow
**Status Flow:** `todo` â†’ `coding_done` â†’ `validated` â†’ `complete` (with `needs_fixes` loop)

**Agent Responsibilities:**
- **Language agents** (jsmaster/gopher/thesnake/etc): `todo`/`needs_fixes` â†’ `coding_done` (never marks complete)
- **validation agent**: `coding_done` â†’ `validated`/`needs_fixes` (never marks complete)
- **bugsy**: `needs_fixes` â†’ `coding_done` (fixes issues, never marks complete)
- **human/claude**: `validated` â†’ `complete` (final approval only)

**Status Transitions:**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  todo   â”‚â”€â”€â”€â–¶â”‚ coding_done  â”‚â”€â”€â”€â–¶â”‚ validated â”‚â”€â”€â”€â–¶â”‚ complete â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚                   â”‚               â–²
                      â”‚                   â–¼               â”‚
                      â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
                      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚ needs_fixes â”‚â”€â”€â”€â”€â”€â”€â”˜
                                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Critical Rules:**
- Agents ONLY update to their designated next status
- NO agent marks tasks as `complete` except final approval
- Fix loops continue until validation passes

## ğŸš« CRITICAL RULES - FAIL FAST, NO SILENT FALLBACKS

**CRITICAL: Never create silent fallbacks that mask real failures**

### Forbidden Patterns:
- âŒ "If X fails, I'll try Y instead" (without explicit user consent)
- âŒ "This might not work, but here's a workaround" 
- âŒ Creating backup solutions when primary approach should be fixed
- âŒ Assuming alternative approaches without validating the original failure

### Required Behavior:
- âœ… **Fail loudly**: Report exact error and stop
- âœ… **Fail fast**: Don't continue with broken foundations  
- âœ… **Fail explicitly**: Ask user how to proceed with failures
- âœ… **Fix root cause**: Don't work around problems

### Exception Handling:
```
if (primaryApproach.fails()) {
    store_daddy("Primary approach failed: [exact error]")
    throw Error("Cannot proceed - primary approach failed")
    // NO automatic fallbacks without explicit user choice
}
```

### User Communication:
"The primary approach failed with: [error]. Would you like me to:
1. Debug and fix the root cause
2. Try a different approach (specify which)
3. Research alternative solutions"

### Security (NEVER SKIP)
- **SQL**: Use parameters `cursor.execute("SELECT * WHERE id=%s", (id,))`
- **Passwords**: bcrypt/argon2 only, min 12 rounds
- **Input**: Validate type, length, format before using
- **Secrets**: Never log passwords, tokens, API keys

### Before Changing Code
1. **Read** the file first (no assumptions)
2. **Verify** imports/APIs exist
3. **Test** changes actually work
4. **Remember** solutions for next time

### Memory Checkpoints
Every 10-15 messages or before context reset:
```
store_daddy: Current state, decisions, next steps (concise, <500 chars)
```

## ğŸ› ï¸ TOOLS PRIORITY

1. **store_daddy/recall_daddy**: Store everything important (max 5 retrieval)
2. **add_task/get_task**: Track requirements and validation
3. **Read/Grep/Glob**: Verify before claiming
4. **TodoWrite**: Track multi-step work
5. **validation agent**: Check work against requirements
6. **Test execution**: Validate fixes work

## âš ï¸ COMMON FAILURES

**LLMs often:**
- Assume file contents â†’ Always Read first
- Invent APIs â†’ Verify with Grep
- Forget earlier decisions â†’ Check recall_daddy
- Skip validation â†’ Use validation agent with task ID
- Skip testing â†’ Run code to confirm

**When stuck:**
1. Store current state
2. Simplify the approach
3. Ask user for direction

## ğŸ¯ SUCCESS CRITERIA

Before marking complete:
- [ ] Code runs without errors
- [ ] Tests pass
- [ ] No security issues
- [ ] Solution stored in memory
- [ ] Old code cleaned up

**Quality gates:**
- If agent output seems incomplete â†’ escalate to thorough mode
- If multiple agents conflict â†’ use opinion agent for decision
- If solution feels complex â†’ verify with appropriate language agent review

**Success metrics (validate before marking complete):**
- Code: Actually runs without errors when executed
- Research: Answers the specific question asked with actionable info
- Fixes: Problem no longer occurs after implementation
- Documentation: User can follow instructions successfully

---
*Remember: Simple + Verified > Complex + Assumed*